# ğŸš€ Resilient Dataset & Artifact Upload System

> **Full-Stack, Production-Ready, Resumable Uploads for AI Datasets & Artifacts**

<div align="center">

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![TypeScript](https://img.shields.io/badge/TypeScript-4.9+-007ACC.svg?logo=typescript)
![React](https://img.shields.io/badge/React-18.2+-61DAFB.svg?logo=react)
![Node.js](https://img.shields.io/badge/Node.js-18+-339933.svg?logo=node.js)
![Express](https://img.shields.io/badge/Express-4.18+-000000.svg?logo=express)

### ğŸ¯ Production-Ready â€¢ Scalable â€¢ Resilient â€¢ AI-First

</div>

---

## ğŸ“š Table of Contents

- [ğŸ What This System Solves](#-what-this-system-solves)
- [ğŸ—ï¸ High-Level Architecture](#ï¸-high-level-architecture)
- [âœ¨ Core Capabilities](#-core-capabilities)
- [ğŸ¨ System Design View](#-system-design-view)
- [ğŸ“ Repository Structure](#-repository-structure)
- [ğŸ–¥ï¸ Frontend (React) Overview](#ï¸-frontend-react-overview)
- [ğŸ’» Backend (Node/Express) Overview](#-backend-nodeexpress-overview)
- [ğŸ¤– AI Integration Points](#-ai-integration-points)
- [ğŸš€ Deployment & Scaling](#-deployment--scaling)
- [ğŸ“Š Observability & Performance](#-observability--performance)
- [ğŸ”’ Security & Compliance](#-security--compliance)
- [ğŸ§± Future Evolution & System Design Notes](#-future-evolution--system-design-notes)

---

## ğŸ What This System Solves

Uploading large AI datasets and artifacts is **hard**:

- Networks are flaky.
- Browsers crash.
- Files are huge.
- Compliance & PII checks are non-negotiable.
- AI pipelines expect files to be validated, preprocessed, and cataloged.

This system provides a **resilient, resumable, chunked upload pipeline** with:

- **Chunk-level idempotency**
- **Auto-resume & missing-chunk discovery**
- **Backend reassembly into durable object storage (S3/MinIO)**
- **AI-specific plumbing** (validation, PII detection, fine-tuning & embeddings pipeline hooks)

---

## ğŸ—ï¸ High-Level Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        UI[ğŸ¨ React Upload UI]
        CM[ğŸ“¦ Chunk Manager]
        ST[ğŸ§  Upload State & Resume Cache]
    end

    subgraph "API Gateway / Edge"
        RL[ğŸ›¡ï¸ Rate Limiter]
        AUTH[ğŸ” Auth & RBAC]
        LB[âš–ï¸ Load Balancer]
    end

    subgraph "Backend Services"
        ES[ğŸŒ Express API]
        US[ğŸ“‚ Upload Service]
        CHS[ğŸ§± Chunk Service]
        VS[âœ… Validation Service]
        AIS[ğŸ¤– AI Integration Service]
        MS[(ğŸ—„ï¸ Metadata Store)]
        CCH[(âš¡ Redis Cache)]
    end

    subgraph "Storage & AI Layer"
        S3[(ğŸ“¦ S3 / Object Storage)]
        PG[(ğŸ’½ PostgreSQL)]
        FT[ğŸ§¬ Fine-Tuning Pipeline]
        EMB[ğŸ“ Embedding Service]
        PII[ğŸ•µï¸ PII Scanner]
        SCV[ğŸ“‘ Schema Validator]
    end

    UI --> CM --> ST
    CM --> RL --> AUTH --> LB --> ES
    ES --> US --> MS
    ES --> CHS --> S3
    US --> CCH
    US --> PG
    ES --> VS --> SCV
    VS --> PII
    S3 --> FT
    S3 --> EMB
```

---

## âœ¨ Core Capabilities

### ğŸ¯ Upload & Resilience

- **Chunked Uploads** (default 1 MB chunks)
- **Parallel Uploads** with configurable concurrency
- **Idempotent Chunk Handling** via Redis metadata
- **Auto-Resume** by asking backend for **missing chunks**
- **End-to-End Progress Visualization** per chunk & overall %
- **Safe Retry** with exponential backoff

### ğŸ¤– AI-First Features

- **Dataset Validation**
  - File type, size, checksum
  - Schema validation (JSON/JSONL/CSV etc.)
- **PII Detection**
  - Regex + ML-based scanning hooks
- **Metadata Extraction & Cataloging**
  - Dataset stats, fields, row counts, semantics
- **Pipeline Triggers**
  - Fine-tuning datasets
  - Embedding generation
  - Training/Indexing workflows

---

## ğŸ¨ System Design View

### ğŸ§© Component Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Upload UI  â€¢ Chunk Manager â€¢ State Machine â€¢ Resume Cache â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                    â–²
                 â–¼                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway / Edge                      â”‚
â”‚   HTTPS â€¢ Auth â€¢ Rate Limiting â€¢ Load Balancing            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (Express + TS)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Routes â€¢ Controllers â€¢ Services â€¢ Validation â€¢ Metrics      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚                 â”‚
       â–¼             â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Cache â”‚ â”‚ PostgreSQL   â”‚ â”‚ Object Store â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                â”‚
       â””â”€â”€â”€â”€â”€â”€â–º   AI Pipelines & Jobs â—„â”€â”˜
                 (Fine-tuning, Embeddings, PII, etc.)
```

### ğŸ” End-to-End Upload Flow

```mermaid
sequenceDiagram
    participant U as User Browser
    participant FE as React Frontend
    participant BE as Express Backend
    participant RS as Redis/DB
    participant S3 as Object Storage
    participant AI as AI Pipelines

    U->>FE: Select large dataset
    FE->>BE: POST /upload/init (metadata, checksum)
    BE->>RS: Create upload session (totalChunks, status=INIT)
    BE-->>FE: uploadId, chunkSize, totalChunks

    loop for each chunk (parallel)
        FE->>BE: POST /upload/chunk (uploadId, chunkIndex, data)
        BE->>RS: Check if chunk already exists
        alt not exists
            BE->>S3: Put temp chunk
            BE->>RS: Store chunk metadata
        end
        BE-->>FE: {status: uploaded/already_uploaded}
    end

    FE->>BE: POST /upload/complete
    BE->>S3: Reassemble chunks into final object
    BE->>RS: Validate checksum & update status=COMPLETED
    BE->>AI: Trigger async jobs (PII, schema, embeddings, fine-tune)
    AI-->>BE: Job status updates
```

---

## ğŸ“ Repository Structure

```bash
.
â”œâ”€â”€ README.md                # ğŸ”¹ This file â€“ global overview
â”œâ”€â”€ docker-compose.yml       # Local infra stack (backend, frontend, redis, db, minio, nginx)
â”œâ”€â”€ nginx.conf               # Optional edge configuration
â”œâ”€â”€ backend/                 # ğŸŒ Node.js + Express backend
â”‚   â”œâ”€â”€ README.md            # Backend-specific docs & system design
â”‚   â””â”€â”€ src/...
â””â”€â”€ frontend/                # ğŸ¨ React upload UI
    â”œâ”€â”€ README.md            # Frontend-specific docs & UX/state design
    â””â”€â”€ src/...
```

> ğŸ” For more detailed implementation docs, see:
> - `backend/README.md`
> - `frontend/README.md`

---

## ğŸ–¥ï¸ Frontend (React) Overview

- Written in **TypeScript + React 18**
- Uses **styled-components** and **Framer Motion** for rich UX
- Implements:
  - Drag & drop upload
  - Visual chunk grid (per-chunk status)
  - Pause / Resume
  - Retry failed chunks
  - Real-time progress bars

The frontend exposes a single main component:

- `AIUploadSystem` â€“ orchestrates:
  - **Initialization** (`/upload/init`)
  - **Chunking & queueing**
  - **Parallel uploads & retries**
  - **Completion call** (`/upload/complete`)

ğŸ‘‰ See **`frontend/README.md`** for:
- State machine diagram
- Component breakdown
- How chunk scheduling & retries work
- Theming and customization

---

## ğŸ’» Backend (Node/Express) Overview

- **Node.js 18+**, **Express**, **TypeScript**
- **Redis** for chunk metadata & idempotency
- **PostgreSQL** (or any RDBMS) for upload sessions
- **S3 / MinIO** for durable storage
- Pluggable services:
  - `UploadService`, `ChunkService`, `ValidationService`, `AIIntegrationService`

Key endpoints:

| Method | Path                     | Purpose                          |
|--------|--------------------------|----------------------------------|
| POST   | `/api/upload/init`       | Create an upload session         |
| POST   | `/api/upload/chunk`      | Upload an individual chunk       |
| GET    | `/api/upload/status/:id` | Check status + missing chunks    |
| POST   | `/api/upload/complete`   | Finalize upload & trigger AI     |

ğŸ‘‰ See **`backend/README.md`** for:
- Detailed API contracts
- Data model diagrams
- System design (idempotency, consistency, failure handling)
- How reassembly & cleanup work

---

## ğŸ¤– AI Integration Points

The backend exposes **integration hooks** to plug in your AI infra:

- **PII Detection & Compliance**
- **Schema validation & transformation**
- **Fine-tuning Dataset Preparation**
- **Embedding Generation & Vector DB Upserts**
- **Custom ML / ETL Jobs**

You can implement these by extending `AIIntegrationService` and calling out to:

- Internal ML services
- LLM APIs
- Vector DBs (Pinecone, Qdrant, PGVector, etc.)

Sample pseudo-flow:

```text
Upload Completed
   â””â”€â–º PII Scan
         â”œâ”€â–º PASS â†’ Schema Validation â†’ Metadata Stats â†’ Route to:
         â”‚       â”œâ”€â–º Fine-tuning Jobs
         â”‚       â”œâ”€â–º Embedding Generation
         â”‚       â””â”€â–º Training / Indexing Pipelines
         â””â”€â–º FAIL â†’ Quarantine dataset + notify / block usage
```

---

## ğŸš€ Deployment & Scaling

Supported deployment patterns:

- **Docker Compose** for local / single-node setups
- **Kubernetes** for horizontal scaling:
  - Multi-replica backend
  - HPA based on CPU/memory
  - Persistent Volumes for temp upload buffer if needed
- **Object Storage** decouples storage from compute
- **Redis** as a distributed coordination layer for:
  - Chunk tracking
  - Session state
  - Rate limiting

See the **docker-compose** and **K8s** manifests in this repo and adapt for your environment.

---

## ğŸ“Š Observability & Performance

Backend exposes metrics (e.g., via **Prometheus**):

- `uploads_total{status, file_type}`
- `upload_duration_seconds`
- `chunks_uploaded_total{status}`
- `active_uploads`

Design targets:

- P95 upload-related API latency `< 500ms`
- Chunk success rate `> 99.5%`
- Resume success rate `> 95%`
- Concurrent uploads: 1,000+ (with proper tuning)

---

## ğŸ”’ Security & Compliance

Security features baked in:

- **Auth & RBAC**
- **Strict file-type and size validation**
- **Checksum validation**
- **Rate limiting & DDoS mitigation**
- **PII detection hooks** for GDPR/other regs
- **Audit logging** for all critical operations
- **Secure temporary storage and cleanup**

---

## ğŸ§± Future Evolution & System Design Notes

This system is designed to evolve:

- **From single-node to distributed:**
  - Move from local temp dir to object storage only
  - Use **multi-part uploads** directly to S3 via **pre-signed URLs**
  - Offload CPU-heavy transforms to background workers / queues

- **Consistency & Resilience:**
  - At-least-once delivery of chunks + idempotency
  - Exactly-once semantics for final assembled object
  - Handling **partial failures** (chunk uploaded but Redis metadata lost, etc.)

- **Edge Integration:**
  - API Gateway / sidecar proxies for:
    - mTLS & Auth
    - WAF rules
    - Request shaping / throttling
    - Model-serving adjacency for generated artifacts

For deeper, service-level system design details, see:

- `backend/README.md` â€“ **backend system design**
- `frontend/README.md` â€“ **client-side resilience design**

---

<div align="center">

### ğŸŒŸ Built for AI Engineering Teams Who Care About Reliability ğŸŒŸ

</div>
